---
phase: 03-round-trip-editing
plan: 03
type: execute
wave: 3
depends_on: ["03-01", "03-02"]
files_modified:
  - core/sync/reingest.py
  - core/sync/__init__.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Modified vault files are detected and re-ingested"
    - "Re-ingested content updates StoryGraph without losing manual annotations"
    - "Conflicts between vault and extraction are flagged"
    - "Provenance is tracked for all re-ingested content"
  artifacts:
    - path: "core/sync/reingest.py"
      provides: "Vault to StoryGraph re-ingestion pipeline"
      exports: ["VaultReingester", "ReingestResult"]
  key_links:
    - from: "core/sync/reingest.py"
      to: "core/sync/change_detector.py"
      via: "ChangeDetector for detecting modified files"
      pattern: "ChangeDetector"
    - from: "core/sync/reingest.py"
      to: "core/sync/protected_blocks.py"
      via: "extract_frontmatter, parse_frontmatter_yaml"
      pattern: "frontmatter"
    - from: "core/sync/reingest.py"
      to: "core/sync/conflict_resolver.py"
      via: "ConflictResolver for handling conflicts"
      pattern: "ConflictResolver"
    - from: "core/sync/reingest.py"
      to: "build/storygraph.json"
      via: "JSON read/write"
      pattern: "storygraph"
---

<objective>
Implement the re-ingestion pipeline that syncs vault changes back to StoryGraph.

Purpose: This is the core round-trip functionality - when users edit vault notes, those changes need to be reflected in the StoryGraph while preserving evidence links and flagging conflicts.
Output: VaultReingester class that orchestrates the full re-ingestion flow.
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Research context
@.planning/phases/03-round-trip-editing/03-RESEARCH.md

# Dependencies from Plans 01-02
@core/sync/change_detector.py
@core/sync/protected_blocks.py
@core/sync/provenance.py
@core/sync/conflict_resolver.py

# Existing patterns
@core/canon/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create re-ingestion module</name>
  <files>core/sync/reingest.py, core/sync/__init__.py</files>
  <action>
Create the vault re-ingestion module:

1. Update `core/sync/__init__.py` to export all sync components
2. Create `core/sync/reingest.py`:

```python
"""Vault re-ingestion pipeline.

Syncs changes from Obsidian vault back to StoryGraph:
1. Detect modified vault files
2. Parse vault note content (frontmatter + body)
3. Merge with existing StoryGraph entities
4. Flag conflicts for review
5. Track provenance
"""
import json
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from .change_detector import ChangeDetector
from .conflict_resolver import ConflictResolver, ConflictTier, ConflictStatus
from .protected_blocks import (
    extract_frontmatter,
    parse_frontmatter_yaml,
    has_protected_block,
    extract_protected_content,
)
from .provenance import ProvenanceTracker, SourceType


@dataclass
class ReingestResult:
    """Result of a re-ingestion operation."""
    success: bool
    files_checked: int = 0
    files_changed: int = 0
    entities_updated: int = 0
    entities_created: int = 0
    conflicts_safe: int = 0
    conflicts_ambiguous: int = 0
    conflicts_critical: int = 0
    errors: List[str] = field(default_factory=list)

    def to_dict(self) -> dict:
        return {
            "success": self.success,
            "files_checked": self.files_checked,
            "files_changed": self.files_changed,
            "entities_updated": self.entities_updated,
            "entities_created": self.entities_created,
            "conflicts_safe": self.conflicts_safe,
            "conflicts_ambiguous": self.conflicts_ambiguous,
            "conflicts_critical": self.conflicts_critical,
            "errors": self.errors
        }


class VaultReingester:
    """Orchestrate re-ingestion from vault to StoryGraph."""

    VAULT_DIRS = {
        "character": "10_Characters",
        "location": "20_Locations",
        "scene": "50_Scenes"
    }

    def __init__(self, project_path: Path):
        """
        Initialize re-ingester.

        Args:
            project_path: Path to project root
        """
        self.project_path = Path(project_path)
        self.vault_path = self.project_path / "vault"
        self.build_path = self.project_path / "build"

        # Components
        self.change_detector = ChangeDetector(self.build_path / "run_state.json")
        self.conflict_resolver = ConflictResolver(self.build_path / "conflicts.json")
        self.provenance = ProvenanceTracker(self.build_path / "provenance.json")

        # Loaded storygraph
        self._storygraph: Optional[Dict] = None

    def _load_storygraph(self) -> Dict:
        """Load storygraph.json."""
        if self._storygraph is None:
            path = self.build_path / "storygraph.json"
            if path.exists():
                self._storygraph = json.loads(path.read_text())
            else:
                self._storygraph = {
                    "version": "1.0",
                    "project_id": self.project_path.name,
                    "entities": [],
                    "edges": [],
                    "evidence_index": {}
                }
        return self._storygraph

    def _save_storygraph(self):
        """Save updated storygraph."""
        path = self.build_path / "storygraph.json"
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(json.dumps(self._storygraph, indent=2))

    def detect_vault_changes(self) -> List[Tuple[Path, str]]:
        """
        Find all modified vault files.

        Returns:
            List of (filepath, entity_type) tuples
        """
        changed = []
        for entity_type, subdir in self.VAULT_DIRS.items():
            vault_dir = self.vault_path / subdir
            if vault_dir.exists():
                for filepath in self.change_detector.get_changed_files(vault_dir):
                    changed.append((filepath, entity_type))
        return changed

    def parse_vault_note(self, filepath: Path) -> Optional[Dict[str, Any]]:
        """
        Parse a vault note into structured data.

        Returns:
            Dict with frontmatter, body, protected content, or None on error
        """
        try:
            content = filepath.read_text(encoding="utf-8")

            # Extract frontmatter
            frontmatter_text, body = extract_frontmatter(content)
            if not frontmatter_text:
                return None

            # Parse YAML frontmatter
            frontmatter = parse_frontmatter_yaml(frontmatter_text)
            if not frontmatter.get("id"):
                return None

            # Extract protected block content
            _, protected, _ = extract_protected_content(body)

            return {
                "frontmatter": frontmatter,
                "body": body,
                "protected_content": protected,
                "has_markers": has_protected_block(body),
                "file": str(filepath)
            }
        except Exception as e:
            return None

    def find_entity_in_graph(self, entity_id: str) -> Optional[Dict]:
        """Find entity in StoryGraph by ID."""
        storygraph = self._load_storygraph()
        for entity in storygraph.get("entities", []):
            if entity.get("id") == entity_id:
                return entity
        return None

    def merge_entity(
        self,
        vault_data: Dict,
        existing_entity: Dict
    ) -> Tuple[Dict, List[str]]:
        """
        Merge vault data with existing entity.

        Returns:
            Tuple of (merged entity, list of conflict IDs)
        """
        merged = existing_entity.copy()
        conflict_ids = []
        frontmatter = vault_data["frontmatter"]
        entity_id = frontmatter["id"]
        entity_type = frontmatter.get("type", existing_entity.get("type", ""))
        vault_file = vault_data["file"]

        # Fields to sync from frontmatter
        sync_fields = ["name", "aliases", "int_ext", "time_of_day", "location"]

        for field in sync_fields:
            if field not in frontmatter:
                continue

            vault_value = frontmatter[field]
            existing_value = existing_entity.get(field)

            # Track provenance for vault edit
            self.provenance.track_manual_edit(
                content=vault_value,
                entity_id=entity_id,
                field=field,
                vault_file=vault_file
            )

            # Check for conflict
            conflict = self.conflict_resolver.detect_conflict(
                entity_id=entity_id,
                entity_type=entity_type,
                field=field,
                vault_value=vault_value,
                extracted_value=existing_value,
                vault_file=vault_file,
                evidence_ids=existing_entity.get("evidence_ids", [])
            )

            if conflict:
                conflict_ids.append(conflict.id)

                if conflict.tier == ConflictTier.SAFE:
                    # Auto-merge safe conflicts
                    resolved = self.conflict_resolver.resolve_safe(conflict)
                    merged[field] = resolved
                elif conflict.tier == ConflictTier.AMBIGUOUS:
                    # Flag for review - keep existing value for now
                    pass
                elif conflict.tier == ConflictTier.CRITICAL:
                    # Block - don't change
                    pass
            else:
                # No conflict - update from vault
                merged[field] = vault_value

        # Handle attributes sub-object for scenes/locations
        if "attributes" not in merged:
            merged["attributes"] = {}

        attr_fields = ["int_ext", "time_of_day", "location"]
        for field in attr_fields:
            if field in frontmatter:
                merged["attributes"][field] = frontmatter[field]

        return merged, conflict_ids

    def reingest_file(self, filepath: Path, entity_type: str) -> Optional[str]:
        """
        Re-ingest a single vault file.

        Returns:
            Entity ID if successful, None if skipped/error
        """
        vault_data = self.parse_vault_note(filepath)
        if not vault_data:
            return None

        entity_id = vault_data["frontmatter"].get("id")
        if not entity_id:
            return None

        existing = self.find_entity_in_graph(entity_id)

        if existing:
            # Merge with existing
            merged, _ = self.merge_entity(vault_data, existing)

            # Update in storygraph
            storygraph = self._load_storygraph()
            for i, entity in enumerate(storygraph["entities"]):
                if entity.get("id") == entity_id:
                    storygraph["entities"][i] = merged
                    break
        else:
            # New entity from vault (user-created)
            new_entity = {
                "id": entity_id,
                "type": entity_type,
                "name": vault_data["frontmatter"].get("name", "Unknown"),
                "aliases": vault_data["frontmatter"].get("aliases", []),
                "attributes": {},
                "evidence_ids": [],
                "source": "manual_vault_create"
            }

            # Add type-specific attributes
            if entity_type == "scene":
                new_entity["attributes"]["int_ext"] = vault_data["frontmatter"].get("int_ext", "INT")
                new_entity["attributes"]["time_of_day"] = vault_data["frontmatter"].get("time_of_day", "")
                new_entity["attributes"]["location"] = vault_data["frontmatter"].get("location", "")

            storygraph = self._load_storygraph()
            storygraph["entities"].append(new_entity)

        # Mark as synced
        self.change_detector.mark_synced(filepath)
        return entity_id

    def run(self) -> ReingestResult:
        """
        Execute full re-ingestion pipeline.

        Returns:
            ReingestResult with statistics
        """
        result = ReingestResult(success=True)

        # Load storygraph
        self._load_storygraph()

        # Detect changes
        changed_files = self.detect_vault_changes()
        result.files_checked = sum(
            len(list((self.vault_path / subdir).glob("*.md")))
            for subdir in self.VAULT_DIRS.values()
            if (self.vault_path / subdir).exists()
        )
        result.files_changed = len(changed_files)

        # Process each changed file
        for filepath, entity_type in changed_files:
            try:
                entity_id = self.reingest_file(filepath, entity_type)
                if entity_id:
                    # Check if new or updated
                    existing = self.find_entity_in_graph(entity_id)
                    if existing and existing.get("source") == "manual_vault_create":
                        result.entities_created += 1
                    else:
                        result.entities_updated += 1
            except Exception as e:
                result.errors.append(f"Error processing {filepath}: {str(e)}")

        # Count conflicts by tier
        for conflict in self.conflict_resolver.conflicts:
            if conflict.status == ConflictStatus.PENDING:
                if conflict.tier == ConflictTier.SAFE:
                    result.conflicts_safe += 1
                elif conflict.tier == ConflictTier.AMBIGUOUS:
                    result.conflicts_ambiguous += 1
                else:
                    result.conflicts_critical += 1

        # Save updated storygraph
        self._save_storygraph()

        # Update last sync timestamp
        self.change_detector.update_last_sync()

        return result


def reingest_vault(project_path: Path) -> ReingestResult:
    """
    Convenience function to re-ingest vault.

    Args:
        project_path: Path to project root

    Returns:
        ReingestResult
    """
    reingester = VaultReingester(project_path)
    return reingester.run()
```

3. Update `core/sync/__init__.py`:

```python
"""Sync module for round-trip editing between vault and StoryGraph."""

from .change_detector import ChangeDetector, calculate_file_hash
from .protected_blocks import (
    BEGIN_MARKER,
    END_MARKER,
    extract_protected_content,
    replace_protected_content,
    ensure_markers,
    has_protected_block,
    extract_frontmatter,
    parse_frontmatter_yaml,
)
from .provenance import (
    ProvenanceTracker,
    ProvenanceRecord,
    SourceType,
)
from .conflict_resolver import (
    ConflictResolver,
    Conflict,
    ConflictTier,
    ConflictStatus,
)
from .reingest import (
    VaultReingester,
    ReingestResult,
    reingest_vault,
)

__all__ = [
    # Change detection
    "ChangeDetector",
    "calculate_file_hash",
    # Protected blocks
    "BEGIN_MARKER",
    "END_MARKER",
    "extract_protected_content",
    "replace_protected_content",
    "ensure_markers",
    "has_protected_block",
    "extract_frontmatter",
    "parse_frontmatter_yaml",
    # Provenance
    "ProvenanceTracker",
    "ProvenanceRecord",
    "SourceType",
    # Conflict resolution
    "ConflictResolver",
    "Conflict",
    "ConflictTier",
    "ConflictStatus",
    # Re-ingestion
    "VaultReingester",
    "ReingestResult",
    "reingest_vault",
]
```
</action>
  <verify>python -c "from core.sync import VaultReingester, reingest_vault; print('Import OK')"</verify>
  <done>VaultReingester can detect vault changes and sync to StoryGraph</done>
</task>

</tasks>

<verification>
- VaultReingester imports successfully
- Can detect changed vault files
- Can parse vault notes (frontmatter + body)
- Can merge with existing StoryGraph entities
- Conflicts are detected and flagged
</verification>

<success_criteria>
- `core/sync/reingest.py` with VaultReingester class
- Full pipeline: detect -> parse -> merge -> flag -> save
- ReingestResult with statistics
- Updated __init__.py with all exports
</success_criteria>

<output>
After completion, create `.planning/phases/03-round-trip-editing/03-03-SUMMARY.md`
</output>
