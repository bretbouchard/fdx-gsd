---
phase: 03-round-trip-editing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - core/sync/__init__.py
  - core/sync/change_detector.py
  - core/sync/protected_blocks.py
  - core/sync/provenance.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "File changes are detected via SHA-256 hash comparison"
    - "Protected block markers are parsed and content extracted correctly"
    - "Every content field tracks its source (extraction vs manual edit)"
  artifacts:
    - path: "core/sync/change_detector.py"
      provides: "Hash-based file change detection"
      exports: ["ChangeDetector", "calculate_file_hash"]
    - path: "core/sync/protected_blocks.py"
      provides: "Protected block parsing and replacement"
      exports: ["extract_protected_content", "replace_protected_content", "BEGIN_MARKER", "END_MARKER"]
    - path: "core/sync/provenance.py"
      provides: "Content source tracking"
      exports: ["ProvenanceTracker", "ProvenanceRecord", "SourceType"]
  key_links:
    - from: "core/sync/change_detector.py"
      to: "build/run_state.json"
      via: "JSON persistence"
      pattern: "run_state\\.json"
    - from: "core/sync/protected_blocks.py"
      to: "core/vault/templates.py"
      via: "marker constants"
      pattern: "CONFUCIUS:BEGIN|END"
---

<objective>
Create the foundational sync module with change detection, protected block parsing, and provenance tracking.

Purpose: These are the building blocks that enable round-trip editing. Without change detection, we cannot know what changed. Without protected block parsing, we cannot preserve manual edits. Without provenance, we cannot trace content sources.
Output: New `core/sync/` module with three core components.
</objective>

<execution_context>
@/Users/bretbouchard/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bretbouchard/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Research context
@.planning/phases/03-round-trip-editing/03-RESEARCH.md

# Existing patterns to follow
@core/vault/templates.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create change detection module</name>
  <files>core/sync/__init__.py, core/sync/change_detector.py</files>
  <action>
Create `core/sync/` directory and implement change detection:

1. Create `core/sync/__init__.py` with module exports
2. Create `core/sync/change_detector.py`:

```python
"""Change detection using SHA-256 hashing with mtime optimization."""
import hashlib
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

def calculate_file_hash(filepath: Path, chunk_size: int = 8192) -> str:
    """Calculate SHA-256 hash using chunked reading for large files."""
    hash_obj = hashlib.sha256()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(chunk_size), b''):
            hash_obj.update(chunk)
    return hash_obj.hexdigest()

class ChangeDetector:
    """Track file changes via hash and mtime comparison."""

    def __init__(self, state_path: Path):
        self.state_path = Path(state_path)
        self._state: Dict[str, dict] = {}
        self._load_state()

    def _load_state(self):
        if self.state_path.exists():
            self._state = json.loads(self.state_path.read_text())
        else:
            self._state = {"files": {}, "last_sync": None}

    def _save_state(self):
        self.state_path.parent.mkdir(parents=True, exist_ok=True)
        self.state_path.write_text(json.dumps(self._state, indent=2))

    def has_changed(self, filepath: Path) -> bool:
        """Check if file changed (mtime first, then hash)."""
        filepath_str = str(filepath)
        stored = self._state["files"].get(filepath_str, {})
        stored_mtime = stored.get("mtime")
        current_mtime = filepath.stat().st_mtime

        # Quick rejection: mtime unchanged
        if stored_mtime and current_mtime == stored_mtime:
            return False

        # Definitive check: hash comparison
        current_hash = calculate_file_hash(filepath)
        return current_hash != stored.get("hash")

    def get_changed_files(self, directory: Path, pattern: str = "*.md") -> List[Path]:
        """Get all changed files in directory matching pattern."""
        changed = []
        for filepath in directory.rglob(pattern):
            if filepath.is_file() and self.has_changed(filepath):
                changed.append(filepath)
        return changed

    def mark_synced(self, filepath: Path):
        """Mark file as synced with current hash and mtime."""
        filepath_str = str(filepath)
        self._state["files"][filepath_str] = {
            "hash": calculate_file_hash(filepath),
            "mtime": filepath.stat().st_mtime,
            "synced_at": datetime.now().isoformat()
        }
        self._save_state()

    def mark_all_synced(self, directory: Path, pattern: str = "*.md"):
        """Mark all files in directory as synced."""
        for filepath in directory.rglob(pattern):
            if filepath.is_file():
                self.mark_synced(filepath)

    def get_last_sync(self) -> Optional[str]:
        return self._state.get("last_sync")

    def update_last_sync(self):
        self._state["last_sync"] = datetime.now().isoformat()
        self._save_state()

    def remove_file(self, filepath: Path):
        """Remove file from tracking (for deleted files)."""
        filepath_str = str(filepath)
        if filepath_str in self._state["files"]:
            del self._state["files"][filepath_str]
            self._save_state()
</action>
  <verify>python -c "from core.sync.change_detector import ChangeDetector, calculate_file_hash; print('Import OK')"</verify>
  <done>ChangeDetector class can detect changed files via SHA-256 hash with mtime optimization</done>
</task>

<task type="auto">
  <name>Task 2: Create protected blocks module</name>
  <files>core/sync/protected_blocks.py</files>
  <action>
Create protected block parsing module that handles the marker-based content protection:

1. Create `core/sync/protected_blocks.py`:

```python
"""Protected block parsing for preserving manual edits.

Markers:
  <!-- CONFUCIUS:BEGIN AUTO -->
  ... auto-generated content ...
  <!-- CONFUCIUS:END AUTO -->

Content outside markers is NEVER modified.
"""
import re
from typing import Optional, Tuple

BEGIN_MARKER = "<!-- CONFUCIUS:BEGIN AUTO -->"
END_MARKER = "<!-- CONFUCIUS:END AUTO -->"

# Pattern to match protected block (DOTALL for multiline)
_PROTECTED_PATTERN = re.compile(
    re.escape(BEGIN_MARKER) + r"(.*?)" + re.escape(END_MARKER),
    re.DOTALL
)


def has_protected_block(content: str) -> bool:
    """Check if content has protected block markers."""
    return BEGIN_MARKER in content and END_MARKER in content


def extract_protected_content(content: str) -> Tuple[str, str, str]:
    """
    Extract content into (before, protected, after) sections.

    Returns:
        Tuple of (pre-marker content, protected block content, post-marker content)
        If no markers found, returns (content, "", "")
    """
    match = _PROTECTED_PATTERN.search(content)

    if not match:
        return (content, "", "")

    start = match.start()
    end = match.end()

    before = content[:start]
    protected = match.group(1).strip()
    after = content[end:]

    return (before, protected, after)


def replace_protected_content(content: str, new_content: str) -> str:
    """
    Replace only the protected block, preserving everything else.

    Args:
        content: Original file content
        new_content: New content for protected region (without markers)

    Returns:
        Updated file content with protected block replaced
    """
    before, _, after = extract_protected_content(content)

    if not before and not after and not has_protected_block(content):
        # No markers - append at end
        return content.rstrip() + f"\n\n{BEGIN_MARKER}\n{new_content}\n{END_MARKER}\n"

    return f"{before}{BEGIN_MARKER}\n{new_content}\n{END_MARKER}{after}"


def ensure_markers(content: str) -> str:
    """
    Ensure file has protected block markers.

    If markers missing, appends empty block at end.
    """
    if has_protected_block(content):
        return content
    return content.rstrip() + f"\n\n{BEGIN_MARKER}\n{END_MARKER}\n"


def extract_frontmatter(content: str) -> Tuple[Optional[str], str]:
    """
    Extract YAML frontmatter from content.

    Returns:
        Tuple of (frontmatter text without delimiters, body content)
        If no frontmatter, returns (None, content)
    """
    if not content.startswith("---"):
        return (None, content)

    # Find the closing ---
    end_match = re.search(r'\n---\s*\n', content[3:])
    if not end_match:
        return (None, content)

    end_pos = 3 + end_match.end()
    frontmatter = content[3:end_match.start() + 3].strip()
    body = content[end_pos:]

    return (frontmatter, body)


def parse_frontmatter_yaml(frontmatter: str) -> dict:
    """
    Parse simple YAML frontmatter into dict.

    Handles: key: value, key: [list], key: "quoted"
    Does NOT handle nested structures.
    """
    result = {}
    if not frontmatter:
        return result

    for line in frontmatter.split('\n'):
        line = line.strip()
        if not line or ':' not in line:
            continue

        key, value = line.split(':', 1)
        key = key.strip()
        value = value.strip()

        # Parse list format: [item1, item2]
        if value.startswith('[') and value.endswith(']'):
            inner = value[1:-1].strip()
            if inner:
                # Split on comma, strip quotes
                items = []
                for item in inner.split(','):
                    item = item.strip().strip('"\'')
                    if item:
                        items.append(item)
                result[key] = items
            else:
                result[key] = []
        # Parse quoted strings
        elif value.startswith('"') and value.endswith('"'):
            result[key] = value[1:-1]
        elif value.startswith("'") and value.endswith("'"):
            result[key] = value[1:-1]
        # Boolean
        elif value.lower() == 'true':
            result[key] = True
        elif value.lower() == 'false':
            result[key] = False
        # Null
        elif value.lower() in ('null', '~', ''):
            result[key] = None
        else:
            result[key] = value

    return result
</action>
  <verify>python -c "from core.sync.protected_blocks import extract_protected_content, replace_protected_content, BEGIN_MARKER, END_MARKER; print('Import OK')"</verify>
  <done>Protected block parsing can extract, replace, and ensure markers</done>
</task>

<task type="auto">
  <name>Task 3: Create provenance tracking module</name>
  <files>core/sync/provenance.py</files>
  <action>
Create provenance tracking module to trace content sources:

1. Create `core/sync/provenance.py`:

```python
"""Provenance tracking for content source attribution.

Every piece of content knows where it came from:
- extraction: from inbox processing
- manual_edit: user edit in vault
- merge: combined from multiple sources
"""
import hashlib
import json
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Any


class SourceType(Enum):
    """Type of content source."""
    EXTRACTION = "extraction"
    MANUAL_EDIT = "manual_edit"
    MERGE = "merge"


@dataclass
class ProvenanceRecord:
    """Track where content came from."""
    content_hash: str
    source_type: SourceType
    entity_id: str
    field: str
    source_file: Optional[str] = None  # For extraction: inbox file
    vault_file: Optional[str] = None   # For manual_edit: vault file
    timestamp: str = ""
    evidence_ids: List[str] = field(default_factory=list)
    previous_hash: Optional[str] = None  # For tracking changes

    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()

    def to_dict(self) -> dict:
        return {
            "content_hash": self.content_hash,
            "source_type": self.source_type.value,
            "entity_id": self.entity_id,
            "field": self.field,
            "source_file": self.source_file,
            "vault_file": self.vault_file,
            "timestamp": self.timestamp,
            "evidence_ids": self.evidence_ids,
            "previous_hash": self.previous_hash
        }

    @classmethod
    def from_dict(cls, data: dict) -> "ProvenanceRecord":
        return cls(
            content_hash=data["content_hash"],
            source_type=SourceType(data["source_type"]),
            entity_id=data["entity_id"],
            field=data["field"],
            source_file=data.get("source_file"),
            vault_file=data.get("vault_file"),
            timestamp=data.get("timestamp", ""),
            evidence_ids=data.get("evidence_ids", []),
            previous_hash=data.get("previous_hash")
        )


class ProvenanceTracker:
    """Track content provenance across round-trips."""

    def __init__(self, provenance_path: Path):
        self.provenance_path = Path(provenance_path)
        self.records: Dict[str, ProvenanceRecord] = {}
        self._load()

    def _load(self):
        """Load existing provenance records."""
        if self.provenance_path.exists():
            data = json.loads(self.provenance_path.read_text())
            for key, record_data in data.get("records", {}).items():
                self.records[key] = ProvenanceRecord.from_dict(record_data)

    def _save(self):
        """Persist provenance to disk."""
        self.provenance_path.parent.mkdir(parents=True, exist_ok=True)
        data = {
            "version": "1.0",
            "updated_at": datetime.now().isoformat(),
            "records": {k: v.to_dict() for k, v in self.records.items()}
        }
        self.provenance_path.write_text(json.dumps(data, indent=2))

    def _make_key(self, entity_id: str, field: str) -> str:
        """Create unique key for entity field."""
        return f"{entity_id}:{field}"

    def _hash_content(self, content: Any) -> str:
        """Create hash for any content."""
        if isinstance(content, str):
            return hashlib.sha256(content.encode()).hexdigest()[:16]
        elif isinstance(content, list):
            return hashlib.sha256(str(sorted(content)).encode()).hexdigest()[:16]
        else:
            return hashlib.sha256(str(content).encode()).hexdigest()[:16]

    def track_extraction(
        self,
        content: Any,
        entity_id: str,
        field: str,
        source_file: str,
        evidence_ids: List[str]
    ) -> ProvenanceRecord:
        """Track content from extraction."""
        key = self._make_key(entity_id, field)
        content_hash = self._hash_content(content)

        # Get previous hash if exists
        previous = self.records.get(key)
        previous_hash = previous.content_hash if previous else None

        record = ProvenanceRecord(
            content_hash=content_hash,
            source_type=SourceType.EXTRACTION,
            entity_id=entity_id,
            field=field,
            source_file=source_file,
            vault_file=None,
            evidence_ids=evidence_ids,
            previous_hash=previous_hash
        )

        self.records[key] = record
        self._save()
        return record

    def track_manual_edit(
        self,
        content: Any,
        entity_id: str,
        field: str,
        vault_file: str
    ) -> ProvenanceRecord:
        """Track content from manual vault edit."""
        key = self._make_key(entity_id, field)
        content_hash = self._hash_content(content)

        previous = self.records.get(key)
        previous_hash = previous.content_hash if previous else None

        record = ProvenanceRecord(
            content_hash=content_hash,
            source_type=SourceType.MANUAL_EDIT,
            entity_id=entity_id,
            field=field,
            source_file=None,
            vault_file=vault_file,
            evidence_ids=[],
            previous_hash=previous_hash
        )

        self.records[key] = record
        self._save()
        return record

    def track_merge(
        self,
        content: Any,
        entity_id: str,
        field: str,
        merged_from: List[str]
    ) -> ProvenanceRecord:
        """Track content from merge operation."""
        key = self._make_key(entity_id, field)
        content_hash = self._hash_content(content)

        previous = self.records.get(key)
        previous_hash = previous.content_hash if previous else None

        record = ProvenanceRecord(
            content_hash=content_hash,
            source_type=SourceType.MERGE,
            entity_id=entity_id,
            field=field,
            source_file=None,
            vault_file=None,
            evidence_ids=merged_from,
            previous_hash=previous_hash
        )

        self.records[key] = record
        self._save()
        return record

    def get_source(self, entity_id: str, field: str) -> Optional[ProvenanceRecord]:
        """Get provenance for specific content."""
        return self.records.get(self._make_key(entity_id, field))

    def get_entity_history(self, entity_id: str) -> List[ProvenanceRecord]:
        """Get all provenance records for an entity."""
        prefix = f"{entity_id}:"
        return [r for k, r in self.records.items() if k.startswith(prefix)]

    def has_changed_since_extraction(self, entity_id: str, field: str) -> bool:
        """Check if field was modified manually after extraction."""
        record = self.get_source(entity_id, field)
        if not record:
            return False
        return record.source_type == SourceType.MANUAL_EDIT
</action>
  <verify>python -c "from core.sync.provenance import ProvenanceTracker, ProvenanceRecord, SourceType; print('Import OK')"</verify>
  <done>ProvenanceTracker can track content sources with full history</done>
</task>

</tasks>

<verification>
- All three modules import without errors
- ChangeDetector can detect file changes
- Protected blocks can be extracted and replaced
- Provenance records can be created and persisted
</verification>

<success_criteria>
- `core/sync/__init__.py` exports all classes
- `core/sync/change_detector.py` with ChangeDetector class
- `core/sync/protected_blocks.py` with parsing functions
- `core/sync/provenance.py` with ProvenanceTracker class
- All modules follow existing project patterns (dataclasses, pathlib, json)
</success_criteria>

<output>
After completion, create `.planning/phases/03-round-trip-editing/03-01-SUMMARY.md`
</output>
